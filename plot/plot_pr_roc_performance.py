import os
import numpy as np
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.metrics import precision_recall_curve, roc_curve, auc
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
import xgboost

from dataset.data_reader import DataReader

np.set_printoptions(formatter={'float_kind': lambda x: "{0:0.6f}".format(x)})


def plot_precision_recall_curve(dt_recall, dt_precision, dt_auc, rf_recall, rf_precision, rf_auc, xb_recall, xb_precision, xb_auc, fig_path):
    line_styles = ['dashdot', 'dotted', 'solid', 'dashed']

    plt.title(r'Precision vs. recall AUC')

    plt.grid(True, 'major', 'y', ls='--', lw=.1, c='k', alpha=1)

    plt.plot(dt_recall, dt_precision, linestyle=line_styles[0], color=(0.65, 0.65, 0.65), label='DT (AUC={0})'.format(round(dt_auc, 3)))
    plt.plot(rf_recall, rf_precision, linestyle=line_styles[1], color=(0.50, 0.50, 0.50), label='RF (AUC={0})'.format(round(rf_auc, 3)))
    plt.plot(xb_recall, xb_precision, linestyle=line_styles[2], color=(0.35, 0.35, 0.35), label='XGB (AUC={0})'.format(round(xb_auc, 3)))

    plt.xlabel('Recall', fontsize=10)
    plt.ylabel('Precision', fontsize=10)
    plt.tick_params(labelsize=9)
    plt.legend(loc='best')
    plt.tight_layout()
    plt.savefig(fig_path)

    plt.clf()


def plot_roc(dt_fpr, dt_tpr, dt_auc, rf_fpr, rf_tpr, rf_auc, xb_fpr, xb_tpr, xb_auc, fig_path):
    line_styles = ['dashdot', 'dotted', 'solid', 'dashed']

    plt.title(r'ROC')

    plt.grid(True, 'major', 'y', ls='--', lw=.1, c='k', alpha=1)

    plt.plot(dt_fpr, dt_tpr, linestyle=line_styles[0], color=(0.65, 0.65, 0.65), label='DT (AUC={0})'.format(round(dt_auc, 3)))
    plt.plot(rf_fpr, rf_tpr, linestyle=line_styles[1], color=(0.50, 0.50, 0.50), label='RF (AUC={0})'.format(round(rf_auc, 3)))
    plt.plot(xb_fpr, xb_tpr, linestyle=line_styles[2], color=(0.35, 0.35, 0.35), label='XGB (AUC={0})'.format(round(xb_auc, 3)))

    plt.xlabel('False positive rate', fontsize=10)
    plt.ylabel('True positive rate', fontsize=10)
    plt.tick_params(labelsize=9)
    plt.legend(loc='best')
    plt.tight_layout()
    plt.savefig(fig_path)

    plt.clf()


if __name__ == '__main__':
    feature_file_path = r'D:\python_workspace\feature\malwares_big2015_level4.spa'
    result_dir_path = r'D:\python_workspace\malware_results'
    CNN_IMAGE_SHAPE = (32, 32, 1)
    CNN_EPOCH = 35
    CNN_BATCH_SIZE = 256
    CNN_CHANNEL_ORDER = 'channels_last'

    dataset = DataReader(file_name=feature_file_path).get_dataset()
    dataset.scale()
    dataset.shuffle()

    print(dataset)

    n_classes = len(set(dataset.y))
    X_train, X_test, y_train, y_test = train_test_split(dataset.X, dataset.y, random_state=42)

    decision_tree_classifier = DecisionTreeClassifier(random_state=0)
    decision_tree_classifier.fit(X_train, y_train)

    random_forest_classifier = RandomForestClassifier(n_estimators=100, max_depth=20, random_state=0)
    random_forest_classifier.fit(X_train, y_train)

    xgboost_classifier = xgboost.XGBClassifier(n_estimators=200, max_depth=20, n_jobs=3, learning_rate=0.25, booster='gbtree')
    xgboost_classifier.fit(X_train, y_train)

    y_score_by_decision_tree = decision_tree_classifier.predict_proba(X_test)
    y_score_by_random_forest = random_forest_classifier.predict_proba(X_test)
    y_score_by_xgboost = xgboost_classifier.predict_proba(X_test)

    ### precision recall curve and AUC
    # Decision tree
    precision_by_decision_tree, recall_by_decision_tree, _ = precision_recall_curve(y_test[:, 0], y_score_by_decision_tree[:, 0])
    pr_auc_by_decision_tree = auc(recall_by_decision_tree, precision_by_decision_tree)

    precision, recall, _ = precision_recall_curve(y_test[:, 1], y_score_by_decision_tree[:, 1])
    pr_auc = auc(recall, precision)

    # precision_by_decision_tree = (precision_by_decision_tree + precision) / 2
    # recall_by_decision_tree = (recall_by_decision_tree + recall) / 2
    pr_auc_by_decision_tree = (pr_auc_by_decision_tree + pr_auc) / 2

    # Random Forest
    precision_by_random_forest, recall_by_random_forest, _ = precision_recall_curve(y_test[:, 0], y_score_by_random_forest[:, 0])
    pr_auc_by_random_forest = auc(recall_by_random_forest, precision_by_random_forest)

    precision, recall, _ = precision_recall_curve(y_test[:, 1], y_score_by_random_forest[:, 1])
    pr_auc = auc(recall, precision)

    # precision_by_random_forest = (precision_by_random_forest + precision) / 2
    # recall_by_random_forest = (recall_by_random_forest + recall) / 2
    pr_auc_by_random_forest = (pr_auc_by_random_forest + pr_auc) / 2

    # XGBoost
    precision_by_xgboost, recall_by_xgboost, _ = precision_recall_curve(y_test[:, 0], y_score_by_xgboost[:, 0])
    pr_auc_by_xgboost = auc(recall_by_xgboost, precision_by_xgboost)

    precision, recall, _ = precision_recall_curve(y_test[:, 1], y_score_by_xgboost[:, 1])
    pr_auc = auc(recall, precision)

    # precision_by_xgboost = (precision_by_xgboost + precision) / 2
    # recall_by_xgboost = (recall_by_xgboost + recall) / 2
    pr_auc_by_xgboost = (pr_auc_by_xgboost + pr_auc) / 2

    print('***Precision recall curve results***')
    print('[Decision tree]')
    print('\tprecision recall auc = {0}'.format(pr_auc_by_decision_tree))
    print('\taverage = {0}'.format(np.average(pr_auc_by_decision_tree)))
    print('[Random Forest]')
    print('\tprecision recall auc = {0}'.format(pr_auc_by_random_forest))
    print('\taverage = {0}'.format(np.average(pr_auc_by_random_forest)))
    print('[XGBoost]')
    print('\tprecision recall auc = {0}'.format(pr_auc_by_xgboost))
    print('\taverage = {0}'.format(np.average(pr_auc_by_xgboost)))

    plot_precision_recall_curve(recall_by_decision_tree, precision_by_decision_tree, np.average(pr_auc_by_decision_tree),
                                recall_by_random_forest, precision_by_random_forest, np.average(pr_auc_by_random_forest),
                                recall_by_xgboost, precision_by_xgboost, np.average(pr_auc_by_xgboost),
                                os.path.join(result_dir_path, 'malwares_big2015_level4_prc.png'))


    ### ROC curve and AUC
    # Decision tree
    fpr_by_decision_tree, tpr_by_decision_tree, _ = roc_curve(y_test[:, 0], y_score_by_decision_tree[:, 0])
    roc_auc_by_decision_tree = auc(fpr_by_decision_tree, tpr_by_decision_tree)

    fpr, tpr, _ = roc_curve(y_test[:, 1], y_score_by_decision_tree[:, 1])
    roc_auc = auc(fpr, tpr)

    # fpr_by_decision_tree = (fpr_by_decision_tree + fpr) / 2
    # tpr_by_decision_tree = (tpr_by_decision_tree + tpr) / 2
    roc_auc_by_decision_tree = (roc_auc_by_decision_tree + roc_auc) / 2

    # Random Forest
    fpr_by_random_forest, tpr_by_random_forest, _ = roc_curve(y_test[:, 0], y_score_by_random_forest[:, 0])
    roc_auc_by_random_forest = auc(fpr_by_random_forest, tpr_by_random_forest)

    fpr, tpr, _ = roc_curve(y_test[:, 1], y_score_by_random_forest[:, 1])
    roc_auc = auc(fpr, tpr)

    # fpr_by_random_forest = (fpr_by_random_forest + fpr) / 2
    # tpr_by_random_forest = (tpr_by_random_forest + tpr) / 2
    roc_auc_by_random_forest = (roc_auc_by_random_forest + roc_auc) / 2

    # XGBoost
    fpr_by_xgboost, tpr_by_xgboost, _ = roc_curve(y_test[:, 0], y_score_by_xgboost[:, 0])
    roc_auc_by_xgboost = auc(fpr_by_xgboost, tpr_by_xgboost)

    fpr, tpr, _ = roc_curve(y_test[:, 1], y_score_by_xgboost[:, 1])
    roc_auc = auc(fpr, tpr)

    # fpr_by_xgboost = (fpr_by_xgboost + fpr) / 2
    # tpr_by_xgboost = (tpr_by_xgboost + tpr) / 2
    roc_auc_by_xgboost = (roc_auc_by_xgboost + roc_auc) / 2

    print('***ROC results***')
    print('[Decision tree]')
    print('\tROC auc = {0}'.format(roc_auc_by_decision_tree))
    print('\taverage = {0}'.format(np.average(roc_auc_by_decision_tree)))
    print('[Random Forest]')
    print('\tROC auc = {0}'.format(roc_auc_by_random_forest))
    print('\taverage = {0}'.format(np.average(roc_auc_by_random_forest)))
    print('[XGBoost]')
    print('\tROC auc = {0}'.format(roc_auc_by_xgboost))
    print('\taverage = {0}'.format(np.average(roc_auc_by_xgboost)))

    plot_roc(fpr_by_decision_tree, tpr_by_decision_tree, np.average(roc_auc_by_decision_tree),
             fpr_by_random_forest, tpr_by_random_forest, np.average(roc_auc_by_random_forest),
             fpr_by_xgboost, tpr_by_xgboost, np.average(roc_auc_by_xgboost),
             os.path.join(result_dir_path, 'malwares_big2015_level4_roc.png'))

